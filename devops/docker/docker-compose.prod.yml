# OmniCare EMR Docker Compose Configuration
# Production environment with enhanced security and performance

version: '3.8'

services:
  # PostgreSQL Database - Production
  database:
    build:
      context: ../../
      dockerfile: devops/docker/database/Dockerfile
    container_name: omnicare-database-prod
    restart: always
    environment:
      POSTGRES_DB: omnicare_emr
      POSTGRES_USER: omnicare_user
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
      PGDATA: /var/lib/postgresql/data/pgdata
    secrets:
      - db_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - postgres_logs:/var/log/postgresql
      - ./database/backups:/backups:ro
    networks:
      - omnicare-backend
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U omnicare_user -d omnicare_emr"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Redis Cache - Production
  redis:
    image: redis:7-alpine
    container_name: omnicare-redis-prod
    restart: always
    command: redis-server /usr/local/etc/redis/redis.conf
    volumes:
      - redis_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    networks:
      - omnicare-backend
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Backend API Service - Production
  backend:
    build:
      context: ../../
      dockerfile: devops/docker/backend/Dockerfile
      target: production
    container_name: omnicare-backend-prod
    restart: always
    environment:
      NODE_ENV: production
      PORT: 3001
      DATABASE_URL_FILE: /run/secrets/database_url
      REDIS_URL_FILE: /run/secrets/redis_url
      JWT_SECRET_FILE: /run/secrets/jwt_secret
      MEDPLUM_BASE_URL: ${MEDPLUM_BASE_URL}
      MEDPLUM_CLIENT_ID_FILE: /run/secrets/medplum_client_id
      MEDPLUM_CLIENT_SECRET_FILE: /run/secrets/medplum_client_secret
    secrets:
      - database_url
      - redis_url
      - jwt_secret
      - medplum_client_id
      - medplum_client_secret
    volumes:
      - backend_logs:/app/logs
    networks:
      - omnicare-backend
      - omnicare-frontend
    depends_on:
      database:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Frontend Web Application - Production
  frontend:
    build:
      context: ../../
      dockerfile: devops/docker/frontend/Dockerfile
      target: production
    container_name: omnicare-frontend-prod
    restart: always
    environment:
      NODE_ENV: production
      NEXT_PUBLIC_API_URL: https://api.omnicare.example.com
      NEXT_PUBLIC_MEDPLUM_BASE_URL: ${MEDPLUM_BASE_URL}
      NEXT_TELEMETRY_DISABLED: 1
    networks:
      - omnicare-frontend
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Load Balancer/Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: omnicare-nginx-prod
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.prod.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./ssl-certs:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    networks:
      - omnicare-frontend
    depends_on:
      - frontend
      - backend
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Monitoring - Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: omnicare-prometheus-prod
    restart: always
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    volumes:
      - ./monitoring/prometheus.prod.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    networks:
      - omnicare-monitoring
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Monitoring - Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: omnicare-grafana-prod
    restart: always
    environment:
      GF_SECURITY_ADMIN_PASSWORD_FILE: /run/secrets/grafana_password
      GF_SECURITY_SECRET_KEY_FILE: /run/secrets/grafana_secret_key
      GF_INSTALL_PLUGINS: grafana-piechart-panel
    secrets:
      - grafana_password
      - grafana_secret_key
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    networks:
      - omnicare-monitoring
    depends_on:
      - prometheus
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Log Aggregation - ELK Stack
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: omnicare-elasticsearch-prod
    restart: always
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD_FILE=/run/secrets/elastic_password
    secrets:
      - elastic_password
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - omnicare-monitoring
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: omnicare-logstash-prod
    restart: always
    volumes:
      - ./monitoring/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./monitoring/logstash/config:/usr/share/logstash/config:ro
    networks:
      - omnicare-monitoring
    depends_on:
      - elasticsearch
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: omnicare-kibana-prod
    restart: always
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
      ELASTICSEARCH_USERNAME: elastic
      ELASTICSEARCH_PASSWORD_FILE: /run/secrets/elastic_password
    secrets:
      - elastic_password
    networks:
      - omnicare-monitoring
    depends_on:
      - elasticsearch
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

# Docker secrets for production
secrets:
  db_password:
    external: true
  database_url:
    external: true
  redis_url:
    external: true
  jwt_secret:
    external: true
  medplum_client_id:
    external: true
  medplum_client_secret:
    external: true
  grafana_password:
    external: true
  grafana_secret_key:
    external: true
  elastic_password:
    external: true

# Production volumes with backup strategy
volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/omnicare/data/postgres
  postgres_logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/omnicare/logs/postgres
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/omnicare/data/redis
  backend_logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/omnicare/logs/backend
  nginx_logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/omnicare/logs/nginx
  prometheus_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/omnicare/data/prometheus
  grafana_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/omnicare/data/grafana
  elasticsearch_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/omnicare/data/elasticsearch

# Production networks with isolation
networks:
  omnicare-frontend:
    driver: bridge
    internal: false
  omnicare-backend:
    driver: bridge
    internal: true
  omnicare-monitoring:
    driver: bridge
    internal: true